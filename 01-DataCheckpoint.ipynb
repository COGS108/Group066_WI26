{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Brian Liu: Conceptualization, Analysis, Writing – original draft\n",
    "- Anchita Dash:  Data curation,  Experimental investigation, Writing – original draft\n",
    "- Zihan Zhang:  Project administration, Visualization, Writing – original draft\n",
    "- Ariane Hai: Background research, Methodology, Writing – original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using statistical inference, what are the top predictive features among quantitative game statistics—such as total ratings, install milestones, and growth rates—that determine a game's specific rank within the Google Play Store’s genre-specific top 100 charts? Furthermore, does the relative importance of these features vary significantly across different game genres? \n",
    "\n",
    "**Target variable**   \n",
    "- **rank** (ordinal/numerical: the game’s rank (1–100) in the genre’s top 100 list) \n",
    "\n",
    "**Predictor variables** \n",
    "- **total ratings** (numerical: game’s total number of ratings) \n",
    "- **installs** (ordinal/numerical: game’s approximate install milestone—e.g., 100.0 M installs vs. 500.0 M installs) \n",
    "- **average rating** (numerical: average rating out of 5)  \n",
    "- **growth (30 days)** (numerical: percent growth in 30 days)  \n",
    "- **growth (60 days)** (numerical: percent growth in 60 days) \n",
    "- **price** (numerical: price in dollars)   \n",
    "- **5 star ratings** (numerical: number of 5 star ratings) \n",
    "\n",
    "**Grouping variable**\n",
    "- **category** (nominal: genre of the game) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google Play Store is the top distributor of downloadable content for Android devices. Run by Google as Android's official app store, it offers apps, games, books, movies, TV, and other media<sup><a href=\"#ref1\">1</a></sup>. As of 2024, the Google Play Store offered approximately 264,000 mobile games ranging across genres like Action, Puzzle, and RPG<sup><a href=\"#ref2\">2</a></sup>. Within this ecosystem, top chart rankings play an important role in influencing which games users actually see and download. Higher ranked games receive more visibility in lists, search results, and curated sections, which in turn increases the likelihood that users will click through and install them<sup><a href=\"#ref3\">3</a></sup>. However, since Google does not disclose its full algorithm behind rankings, it remains unclear which measurable performance metrics, such as install volume, rating averages, or review counts, most strongly predict a game's chart position<sup><a href=\"#ref3\">3</a></sup>.\n",
    "\n",
    "From our own experience scrolling through the Play Store, we noticed that we almost always check the star rating and number of reviews before downloading a game. If an app has a high average rating and thousands of reviews, it just feels more trustworthy than one with barely any feedback. So, we hypothesize that review count and average star rating will be the features most strongly correlated with a game's ranking. With hundreds of thousands of games competing for attention on the Play Store, pinpointing the very factors that increase the attraction of games will help game developers to focus their resources on improving in those specific areas instead of guessing what might work. This gap motivates our analysis: We seek to identify which quantitative signals in the Play Store data correlate most closely with ranking, thereby shedding light on the factors that likely drive discoverability in this marketplace. The \"Top Games on Google Play Store\" dataset provides rankings for the top 100 games across multiple genres, allowing us to analyze whether the relative importance of these predictive factors varies significantly between categories like Action, Puzzle, and RPG.\n",
    "\n",
    "Prior studies indicate that publishers' prior release volume, intragenre ranking, consumer ratings, and review volume jointly drive high levels of game downloads, with the influence of any single information cue varying depending on the presence of other coexisting cues<sup><a href=\"#ref4\">4</a></sup>. Complementary research using TAM and IDT based feature selection methods further shows that mobile game downloads are shaped by both usability perceptions, such as perceived ease of use and usefulness, and diffusion-related factors, including visibility, trialability, and social communication channels<sup><a href=\"#ref5\">5</a></sup>. Together, these findings suggest that download performance emerges from interacting quantitative and contextual signals, a premise that directly informs our investigation of how such signals translate into genre specific ranking outcomes on the Google Play Store and similar app distribution platforms.\n",
    "\n",
    "From the Google Play Store project<sup><a href=\"#ref6\">6</a></sup>, something that we could incorporate into our project are the different graphs that are present. The bar plot that outlines the number of paid and free apps based on category is very useful to see if the category in particular affects the ranking. The project also does a great job of looking at how ratings differ between paid and free apps. This is something that we could also incorporate into our project and see how pricing affects ranking. The correlation matrix is also useful since we are trying to figure out which features strongly influence rankings and this matrix summarizes it well by finding the correlation between ranking and other features. From the app store project<sup><a href=\"#ref7\">7</a></sup>, something that we could incorporate into our project is making a pipeline since that is nice especially if we want new unclean and untidy data for prediction to go through the same processes that we undertook for data cleaning/preprocessing in our project since that would make sure that the new data is fit for modeling and prediction. There were different ML models used like linear regression, SVM regression, polynomial regression etc. and their RMSE were compared, this is also nice if we want to see how each model performs on the validation set and use the best one later for the test set.\n",
    "\n",
    "**References**\n",
    "\n",
    "<a name=\"ref1\"></a> ^ UW Connect. What is Google Play Store. [https://uwconnect.uw.edu/it?id=kb_article_view&sysparm_article=KB0034369](https://uwconnect.uw.edu/it?id=kb_article_view&sysparm_article=KB0034369)\n",
    "\n",
    "<a name=\"ref2\"></a> ^ Statista. (2024). Number of available gaming apps in the Google Play Store. [https://www.statista.com/statistics/780229/number-of-available-gaming-apps-in-the-google-play-store-quarter/](https://www.statista.com/statistics/780229/number-of-available-gaming-apps-in-the-google-play-store-quarter/)\n",
    "\n",
    "<a name=\"ref3\"></a> ^ Appinventiv. How rankings are determined in Google Play Store. [https://appinventiv.com/blog/google-play-store-statistics/](https://appinventiv.com/blog/google-play-store-statistics/)\n",
    "\n",
    "<a name=\"ref4\"></a> ^ Emerald Insight. (2022). The influence of information configuration on mobile game download. [https://www.emerald.com/intr/article-abstract/32/4/1191/176295/The-influence-of-information-configuration-on](https://www.emerald.com/intr/article-abstract/32/4/1191/176295/The-influence-of-information-configuration-on)\n",
    "\n",
    "<a name=\"ref5\"></a> ^ Springer. A Study of Downloading Game Applications. [https://link.springer.com/chapter/10.1007/978-3-662-47200-2_90](https://link.springer.com/chapter/10.1007/978-3-662-47200-2_90)\n",
    "\n",
    "<a name=\"ref6\"></a> ^ Alhajali, A. N. Google Play Store App Dataset Analysis. Kaggle. [https://www.kaggle.com/code/ammarnassanalhajali/google-play-store-app-dataset-analysis/notebook](https://www.kaggle.com/code/ammarnassanalhajali/google-play-store-app-dataset-analysis/notebook)\n",
    "\n",
    "<a name=\"ref7\"></a> ^ Nish, A. Analysis of Apple's App Store. Kaggle. [https://www.kaggle.com/code/avnishnish/analysis-of-apple-s-app-store](https://www.kaggle.com/code/avnishnish/analysis-of-apple-s-app-store)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that total ratings and average rating will be the most statistically significant predictors of chart ranking. Intuitively, these features seem the most pertinent factors for assessing rank. We also anticipate that the relative weight of these features will vary by genre, with total ratings dominating mass-appeal categories like Action, while average rating holds greater predictive power in strategy-focused genres where quality drives retention.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading airline-safety.csv:   0%|          | 0.00/1.23k [00:00<?, ?B/s]\u001b[A\n",
      "                                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: airline-safety.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading bad-drivers.csv:   0%|          | 0.00/1.37k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 2/2 [00:00<00:00, 13.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /home/a1dash/.cache/kagglehub/datasets/dhruvildave/top-play-store-games/3.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72.1k/72.1k [00:00<00:00, 11.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /home/a1dash/.cache/kagglehub/datasets/dhruvildave/top-play-store-games/versions/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dhruvildave/top-play-store-games\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + \"/android-games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1730, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Our dataset only includes the top 100 ranked games per genre, which introduces significant selection bias. By excluding games ranked below 100, we systematically omit indie games, newer releases, and potentially diverse developers who haven't broken into the top charts. This could skew our findings toward characteristics of already-successful games with substantial marketing budgets, potentially reinforcing the advantage of established publishers. We acknowledge this limitation and will interpret our results as applicable to high-ranking games specifically, rather than generalizing to the entire Play Store ecosystem.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "> Our analysis focuses on quantitative metrics visible to users (ratings, installs, growth), but we recognize we lack perspective from game developers who understand the internal factors affecting rankings. Additionally, we do not account for qualitative factors like gameplay innovation, artistic merit, or accessibility features that may influence user satisfaction but not be captured in star ratings. To partially address this, we reviewed existing literature on mobile game success factors and will acknowledge that our statistical model captures correlation, not necessarily the causal mechanisms developers could control.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will use Discord as our primary means of communication. Responses should be within 24 hours. We will meet every Wednesday at Geisel at 5 PM unless notified otherwise through Discord.\n",
    "\n",
    "- We will communicate in a supportive tone with each other. Every message should be responded to. If there is no response needed, always like the message. We will be inclusive of all opinions; no opinion should be rejected without being heard. To express disagreement, we will start with “I personally think.”\n",
    "\n",
    "- Decisions should be made with the consent of all group members. Unless there are significant conflicts, the general rule of thumb should apply. If an immediate decision is needed, at least one other member must agree with the person proposing the decision.\n",
    "\n",
    "- Everyone is expected to do a little bit of everything. Since we all have different strengths, members should be proactive in their area of expertise. Always reach out for help if there is difficulty. Communicate openly if work needs to be split differently.\n",
    "\n",
    "- If a deadline cannot be met, notify the group as soon as possible (at least 36 hours before the deadline). The team will come together to figure out a solution. We commit to being understanding and supportive, with no pressure in communicating these situations. Each member has two chances to request deadline flexibility.\n",
    "\n",
    "- For issues such as problem teammates or conflicts, communicate with the entire group first. The group will decide together whether the issue should be taken outside the group.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discussed At Meeting |\n",
    "|-------------|-------------|--------------------------|----------------------|\n",
    "| 1/21 | 5:00 PM | Reviewed project description and brainstormed initial project ideas | Reviewed project requirements, discussed potential research questions, explored possible datasets, and determined regular meeting times |\n",
    "| 1/28 | 5:00 PM | Conducted background research related to the project topic | Completed project review and refined understanding of project expectations |\n",
    "| 2/3 | 3:20 PM | Reviewed draft project proposal and brainstormed more specific research questions | Began drafting the project proposal, identified and selected datasets, and finalized the research question |\n",
    "| 2/4 | 5:00 PM | Explored and familiarized ourselves with the datasets relevant to the research question | Finished Project Proposal |\n",
    "| 2/11 | 5:00 PM | Reviewed and understood Checkpoint #1 requirements | Began Checkpoint #1, assigned tasks to group members, started dataset preprocessing and initial coding, and discussed wrangling and analytical approaches |\n",
    "| 2/18 | 5:00 PM | Group members completed assigned portions of Checkpoint #1 | Reviewed and finalized Checkpoint #1 |\n",
    "| 2/25 | 5:00 PM | Reviewed EDA and Checkpoint #2 requirements and completed exploratory data analysis using the fully processed dataset | Assigned tasks, loaded cleaned datasets, conducted EDA, and discussed observed patterns and insights |\n",
    "| 3/4 | 5:00 PM | Reviewed final video requirements and brainstormed presentation ideas | Finalized Checkpoint #2, discussed next stages of analysis, planned the final video structure, drafted scripts, and began filming |\n",
    "| 3/11 | 5:00 PM | Filmed individual segments and reviewed recorded clips | Completed filming, re-filmed unsatisfactory clips, and began video editing |\n",
    "| 3/17 | 5:00 PM | Continued editing the final video | Verified all requirements were met and finalized the project |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
